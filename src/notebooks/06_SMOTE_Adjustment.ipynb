{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee00f1a3-8714-45f6-8f47-d556ddbe5fd8",
   "metadata": {},
   "source": [
    "# **06 - SMOTE Adjustment & Hybrid Resampling**\n",
    "\n",
    "## **Objective**\n",
    "In this notebook, we aim to **address the overfitting issue** found in the **SMOTE XGBoost model** by adjusting the **SMOTE ratio** and experimenting with **hybrid resampling techniques**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Why Are We Doing This?**\n",
    "From our **overfitting analysis (Notebook 05)**, we observed that:\n",
    "- **SMOTE XGBoost achieved perfect recall (100%)**, but its precision dropped significantly.\n",
    "- The **learning curve showed minimal generalization gap**, suggesting an **overfitted model**.\n",
    "- Since **SMOTE generates synthetic fraud cases**, it might have **introduced unrealistic patterns**, making the model **too confident**.\n",
    "\n",
    "---\n",
    "\n",
    "## **What We Will Do**\n",
    "1. **Reduce the SMOTE Ratio** → Instead of a strict **1:1 balance**, try **7:3 or 8:2**.\n",
    "2. **Combine SMOTE with Undersampling** → Reduce the majority class slightly **before** applying SMOTE.\n",
    "3. **Re-train & Evaluate New SMOTE Models** → Check if we reduce overfitting while maintaining good recall.\n",
    "\n",
    "---\n",
    "\n",
    "## **Final Goal**\n",
    "- **Find the best SMOTE ratio** that balances **generalization and recall**.\n",
    "- **Prepare a final resampled dataset** that will be used for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd64de1-490c-4302-a9a0-9c3782a3e813",
   "metadata": {},
   "source": [
    "**Imports**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05c1f6c-2c93-4993-8356-47a2b0510939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a997c455-798d-47cd-a1d1-be622e1ad8d9",
   "metadata": {},
   "source": [
    "**Dataset Preparation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa077579-c62f-43b9-ba2d-6dddc38f30c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Scaled Data Shape: (284807, 30)\n",
      "Original Target Shape: (284807, 1)\n",
      "\n",
      "Class distribution before resampling:\n",
      "Class\n",
      "0        0.998273\n",
      "1        0.001727\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the original scaled dataset\n",
    "X = pd.read_csv(\"../datasets/X_scaled.csv\")\n",
    "y = pd.read_csv(\"../datasets/y.csv\")\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Original Scaled Data Shape: {X.shape}\")\n",
    "print(f\"Original Target Shape: {y.shape}\")\n",
    "\n",
    "# Check class distribution before resampling\n",
    "class_distribution = y.value_counts(normalize=True)\n",
    "print(\"\\nClass distribution before resampling:\")\n",
    "print(class_distribution)\n",
    "\n",
    "print(\"\\nData loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9720d3d1-5926-4959-9b6a-bb0118b81a43",
   "metadata": {},
   "source": [
    "**Resampling Strategy Update**:\n",
    "In the previous approach, **SMOTE fully balanced the dataset (1:1 ratio)**, which likely contributed to overfitting. To improve generalization, we will now test **multiple SMOTE ratios (e.g., 70:30, 60:40)** while also slightly undersampling the majority class to find the best balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828a673-5ec0-4ad3-ab67-bb1785f01bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
