{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b4e84a3-2560-4262-a097-ce5335acfef7",
   "metadata": {},
   "source": [
    "# Overfitting Analysis - FraudDetectAI\n",
    "\n",
    "## Understanding Model Generalization\n",
    "\n",
    "Overfitting occurs when a model **performs exceptionally well on training data** but fails to generalize to unseen data.  \n",
    "Since our dataset is highly imbalanced and we applied **SMOTE**, there is a chance that some models may have **memorized synthetic data** rather than learning actual fraud patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## **Objectives of This Notebook**\n",
    "- Compare **training vs. test performance** to detect overfitting.  \n",
    "- Visualize **learning curves** for potential divergence between train & validation loss.  \n",
    "- Analyze **feature importance stability** (does SMOTE make the model over-rely on certain features?).  \n",
    "- Decide whether to **adjust the SMOTE ratio** or introduce **undersampling**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Steps We Will Cover**\n",
    "1. **Compare Train vs. Test Performance** → Precision, Recall, F1-score, AUC-ROC  \n",
    "2. **Plot Learning Curves** → Check whether the model is overfitting  \n",
    "3. **Feature Importance Stability Check** → Compare SHAP values across datasets  \n",
    "4. **Decision on SMOTE Adjustments** → Reduce synthetic samples? Add undersampling?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8532dc14-0d38-47da-835d-4d4c1fa90b67",
   "metadata": {},
   "source": [
    "**Imports**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba5c4e5a-d3da-4bb9-9570-788ff94b88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SHAP for Explainability\n",
    "import shap\n",
    "\n",
    "# Load Saved Models\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dce3a6-1c3a-4872-99ef-fa5aaea0f338",
   "metadata": {},
   "source": [
    "**Data Preparation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acdd357-8ce8-4a71-91ed-9cb70b1ae24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normal dataset\n",
    "X = pd.read_csv(\"../datasets/X_scaled.csv\")\n",
    "y = pd.read_csv(\"../datasets/y.csv\")\n",
    "\n",
    "# Load SMOTE dataset\n",
    "X_smote = pd.read_csv(\"../datasets/X_smote.csv\")\n",
    "y_smote = pd.read_csv(\"../datasets/y_smote.csv\")\n",
    "\n",
    "# Perform Train-Test Split (for Base & Weighted models)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Perform Train-Test Split (for SMOTE model)\n",
    "X_train_smote, _, y_train_smote, _ = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42, stratify=y_smote)\n",
    "\n",
    "# X_test_smote should be the same as X_test (we don't oversample test data)\n",
    "X_test_smote, y_test_smote = X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3171a4a-909d-4fda-846c-b114e2f75dd8",
   "metadata": {},
   "source": [
    "**Model Load**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9294f88-51ac-43c3-bffb-5a57c6131985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models are loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load trained models\n",
    "base_xgb_opt = joblib.load(\"../models/optimized_base_xgb.pkl\")\n",
    "weighted_xgb_opt = joblib.load(\"../models/optimized_weighted_xgb.pkl\")\n",
    "smote_xgb_opt = joblib.load(\"../models/optimized_smote_xgb.pkl\")\n",
    "\n",
    "print(\"Models are loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c07173f-73e0-4535-9741-046defebc745",
   "metadata": {},
   "source": [
    "## Comparing Training vs. Test Performance\n",
    "\n",
    "To detect overfitting, we will compare how well our models perform on **training data vs. test data**.  \n",
    "If a model **performs significantly better on training data** but struggles on the test set, it may be **overfitting**.\n",
    "\n",
    "### **Steps for Evaluation**\n",
    "1. **Make Predictions:**  \n",
    "   - Predict on **X_train** and **X_test** for **Base & Weighted models**.  \n",
    "   - Predict on **X_train_smote** and **X_test_smote** for **SMOTE model**.  \n",
    "\n",
    "2. **Calculate Performance Metrics:**  \n",
    "   - **Precision, Recall, F1-score, AUC-ROC** for both **train and test** sets.  \n",
    "\n",
    "3. **Compare Results:**  \n",
    "   - If **training performance is much higher** than test performance, overfitting is likely.  \n",
    "   - If **metrics are consistent**, our model is generalizing well.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df87bbc6-7a25-4f7a-8043-57dd8420edd8",
   "metadata": {},
   "source": [
    "**Function**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "174dc212-1b32-412b-9fa3-3797929713b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate model performance\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Compute metrics for training set\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "    # Compute metrics for test set\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"Train - Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1-score: {train_f1:.4f}, AUC-ROC: {train_auc:.4f}\")\n",
    "    print(f\"Test  - Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1-score: {test_f1:.4f}, AUC-ROC: {test_auc:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Train Precision\": train_precision,\n",
    "        \"Train Recall\": train_recall,\n",
    "        \"Train F1-score\": train_f1,\n",
    "        \"Train AUC-ROC\": train_auc,\n",
    "        \"Test Precision\": test_precision,\n",
    "        \"Test Recall\": test_recall,\n",
    "        \"Test F1-score\": test_f1,\n",
    "        \"Test AUC-ROC\": test_auc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1932fb7-415f-4be2-adda-9eb8324335af",
   "metadata": {},
   "source": [
    "**Evaluation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2a906b-1b98-4477-b767-67be096a8354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emrev\\PycharmProjects\\FraudDetectAI\\.venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:37:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base XGBoost Performance:\n",
      "Train - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, AUC-ROC: 1.0000\n",
      "Test  - Precision: 0.8925, Recall: 0.8469, F1-score: 0.8691, AUC-ROC: 0.9234\n",
      "\n",
      "Weighted XGBoost Performance:\n",
      "Train - Precision: 0.9975, Recall: 1.0000, F1-score: 0.9987, AUC-ROC: 1.0000\n",
      "Test  - Precision: 0.8617, Recall: 0.8265, F1-score: 0.8438, AUC-ROC: 0.9132\n",
      "\n",
      "SMOTE XGBoost Performance:\n",
      "Train - Precision: 0.9998, Recall: 1.0000, F1-score: 0.9999, AUC-ROC: 0.9999\n",
      "Test  - Precision: 0.5833, Recall: 1.0000, F1-score: 0.7368, AUC-ROC: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Train F1-score</th>\n",
       "      <th>Train AUC-ROC</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test F1-score</th>\n",
       "      <th>Test AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base XGBoost</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>0.8691</td>\n",
       "      <td>0.9234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weighted XGBoost</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.8265</td>\n",
       "      <td>0.8438</td>\n",
       "      <td>0.9132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE XGBoost</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.9994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  Train Precision  Train Recall  Train F1-score  \\\n",
       "0      Base XGBoost           1.0000        1.0000          1.0000   \n",
       "1  Weighted XGBoost           0.9975        1.0000          0.9987   \n",
       "2     SMOTE XGBoost           0.9998        1.0000          0.9999   \n",
       "\n",
       "   Train AUC-ROC  Test Precision  Test Recall  Test F1-score  Test AUC-ROC  \n",
       "0         1.0000          0.8925       0.8469         0.8691        0.9234  \n",
       "1         1.0000          0.8617       0.8265         0.8438        0.9132  \n",
       "2         0.9999          0.5833       1.0000         0.7368        0.9994  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate Base XGBoost Model\n",
    "base_results = evaluate_model(base_xgb_opt, X_train, y_train, X_test, y_test, \"Base XGBoost\")\n",
    "\n",
    "# Evaluate Weighted XGBoost Model\n",
    "weighted_results = evaluate_model(weighted_xgb_opt, X_train, y_train, X_test, y_test, \"Weighted XGBoost\")\n",
    "\n",
    "# Evaluate SMOTE XGBoost Model\n",
    "smote_results = evaluate_model(smote_xgb_opt, X_train_smote, y_train_smote, X_test_smote, y_test_smote, \"SMOTE XGBoost\")\n",
    "\n",
    "# Store results for comparison\n",
    "results_df = pd.DataFrame([base_results, weighted_results, smote_results])\n",
    "\n",
    "# Display full dataframe output in Jupyter\n",
    "pd.set_option(\"display.float_format\", \"{:.4f}\".format)  # Format numbers\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "\n",
    "# Show the results table\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ddeb2-25b7-44b5-9119-21a6842d4c98",
   "metadata": {},
   "source": [
    "## Overfitting Analysis - Train vs. Test Performance  \n",
    "\n",
    "After evaluating model performance on **both training and test sets**, we found some key insights about potential overfitting.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Key Observations:**  \n",
    "1. **Base XGBoost:**  \n",
    "   - **Train F1-score = 1.0000 (Perfect prediction)** → **Possible overfitting**  \n",
    "   - **Test F1-score = 0.8691**, AUC-ROC = 0.9234 → **Decent generalization** but **train is too high**.  \n",
    "\n",
    "2. **Weighted XGBoost:**  \n",
    "   - **Train F1-score = 0.9987 (Almost perfect)** → **Slight overfitting**  \n",
    "   - **Test F1-score = 0.8438**, AUC-ROC = 0.9132 → **Similar to Base XGBoost** but penalizing fraud slightly improved recall.  \n",
    "\n",
    "3. **SMOTE XGBoost:** \n",
    "   - **Train Recall = 1.0000, Precision = 0.9998** → **Overfitting confirmed**  \n",
    "   - **Test Precision = 0.5833**, **Test Recall = 1.0000** → **It’s catching all frauds but also classifying too many non-frauds as fraud!**  \n",
    "   - **Train AUC-ROC = 0.9999 vs. Test AUC-ROC = 0.9994** → **This suggests it memorized synthetic patterns but struggles on real data.**  \n",
    "\n",
    "---\n",
    "\n",
    "### **What Should We Do Next?**  \n",
    "1. **Step 1: Visualize Learning Curves**  \n",
    "   - Plot **Train vs. Test Loss** to **confirm overfitting trends.**  \n",
    "2. **Step 2: Adjust SMOTE Ratio (If Needed)**  \n",
    "   - Instead of **1:1 oversampling**, try **7:3 or 8:2** to keep it more balanced.  \n",
    "3. **Step 3: Consider Undersampling**  \n",
    "   - Combine **SMOTE with undersampling** to **remove unnecessary non-fraud cases.**  \n",
    "\n",
    "---\n",
    "\n",
    "### **Immediate Next Step: Plot Learning Curves**  \n",
    "We will now **visualize training vs. validation loss curves** for all models to **confirm overfitting trends**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b405d-a9a7-468b-871f-3cec3d27c3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
